<html>

<head>
  <title>Gradio</title>
  <link href="static/home/style/style.css" rel="stylesheet">
  {% include 'header.html' %}
</head>

<body>
  <header class="container">
    <img id="logo" src="static/home/img/logo_inline.png" />
    <nav>
      <a class="selected" href="/">Home</a>
      <a href="/getting_started">Getting Started</a>
      <a href="/docs">Docs</a>
      <a href="/ml_examples">ML Examples</a>
      <a href="/hub">Hub</a>
      <a id="contact-link" href="/#contact-box">Contact</a>
    </nav>
  </header>
  <main id="index">
    <div id="hero" class="container">
      <img class="bg-image" src="static/home/img/demo-screenshot-1.jpg" width=360 style="top: 40; left: -40px">
      <img class="bg-image" src="static/home/img/demo-screenshot-5.jpg" width=370 style="top: 200; left: 200px">
      <img class="bg-image" src="static/home/img/demo-screenshot-3.jpg" width=340 style="top: 30; left: 400px">
      <img class="bg-image" src="static/home/img/demo-screenshot-2.jpg" width=340 style="top: 200; left: 680px">
      <img class="bg-image" src="static/home/img/demo-screenshot-4.jpg" width=300 style="top: 50; left: 800px">
      <h2 id="slogan">Interfaces for your ML Models</h2>
      <div id="tagline">Generate an easy-to-use UI for your ML model, function, or API with only a few
        lines of code. Integrate directly into your Python notebook, or share a link with anyone.</div>
      <a class="github-button" href="https://github.com/gradio-app/gradio-UI" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star gradio-app/gradio-UI on GitHub">Star</a>
    </div>
    <div id="tag2" class="container">
      <p>
        <span>Gradio allows you to quickly create customizable UI components around your
          TensorFlow or PyTorch models, or even arbitrary Python functions. Mix and
          match components to support any combination of inputs and outputs. Our core library is free and
          <a href="https://github.com/gradio-app/gradio-UI" target="_blank">open-source</a>!</span>
      </p>
    </div>
    <div id="demos" class="container">
      <p>Below are a few demos. Check the <a href="getting_started">Getting Started</a> for full code examples.</p>
      <div id="demo-nav">
        <button demo="1" class="selected demo-link">
          Digit Classifier
          <div class="demo-type">img &rarr; {label: confidence}</div>
        </button>
        <button demo="2" class="demo-link">
          Q&A with Paragraph
          <div class="demo-type">(text, text) &rarr; text</div>
        </button>
        <button demo="3" class="demo-link">
          Face Segmentation
          <div class="demo-type">webcam &rarr; img</div>
        </button>
        <button demo="4" class="demo-link">
          Outbreak Forecast
          <div class="demo-type">(number, text, list[text], bool) &rarr; plot</div>
        </button>
      </div>
      <div class="demo-window" demo="1">
        <div class="demo-code">
          <div class="codeblock"><code>
              import <varl>gradio</varl> as <varl>gr</varl><br><br>
              def <func>recognize_digit(</func><varl>img</varl><func>)</func>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... implement digit recognition model on input array </comm><br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... return dictionary of labels and confidences </comm><br><br>
              gr.<func>Interface(</func><varl>fn</varl>=<func>recognize_digit</func>, 
              <varl>inputs</varl>="sketchpad", <varl>outputs</varl>="label"<func>)</func>.<func>launch()</func>
            </code></div>
        </div>
        <div class="instructions">
          The single line of code above produces produces the web interface below. Draw a number 0 through 9 on the sketchpad below and click submit to get the model classification!
        </div>
        <div id="interface_1"></div>
      </div>
      <div class="demo-window" demo="2">
        <div class="demo-code">
          <div class="codeblock"><code>
              import <varl>gradio</varl> as <varl>gr</varl><br><br>
              def <func>answer_question(</func><varl>paragraph</varl>, <varl>question</varl><func>)</func>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... implement Q&amp;A model</comm><br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... return answer to question</comm><br><br>
              gr.<func>Interface(</func><varl>fn</varl>=<func>answer_question</func>, 
              <varl>inputs</varl>=["textbox", "text"], <varl>outputs</varl>="text"<func>)</func>.<func>launch()</func>
            </code></div>
        </div>
        <div class="instructions">
          Provide a context paragraph and ask a question that can be answered with the context information. Go ahead, type in some information and a question. Then, click submit to get the answer!
        </div>
        <div id="interface_2"></div>
      </div>      
      <div class="demo-window" demo="3">
        <div class="demo-code">
          <div class="codeblock"><code>
              import <varl>gradio</varl> as <varl>gr</varl><br><br>
              def <func>face_segmentation(</func><varl>img</varl><func>)</func>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... implement face segmentation model on input 200x200 numpy array</comm><br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... return segmentation mask as numpy array</comm><br><br>
              <varl>webcam</varl> = gr.in.Webcam(<varl>shape</varl>=(200, 200))<br>
              gr.<func>Interface(</func><varl>fn</varl>=<func>face_segmentation</func>, 
              <varl>inputs</varl>=webcam, <varl>outputs</varl>="image"<func>)</func>.<func>launch()</func>
            </code></div>
        </div>
        <div class="instructions">
          Take a snapshot from your webcam and click submit to generate a face segmentation.  
        </div>
        <div id="interface_3"></div>
      </div> 
      <div class="demo-window" demo="4">
        <div class="demo-code">
          <div class="codeblock"><code>
              import <varl>gradio</varl> as <varl>gr</varl>, <varl>matplotlib.pyplot</varl> as <varl>plt</varl><br><br>
              def <func>outbreak_forecast(</func><varl>r</varl>, <varl>month</varl>, <varl>countries</varl>, <varl>social_distancing</varl><func>)</func>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... run model to forecast outbreak and generate plots</comm><br>
              &nbsp;&nbsp;&nbsp;&nbsp;<comm># ... return plt</comm><br><br>
              <varl>r</varl> = gr.in.Slider(1, 5)<br>
              <varl>month</varl> = gr.in.Dropdown(["May", "June", "July"])<br>
              <varl>countries</varl> = gr.in.CheckboxGroup(["USA", "Canada", "Mexico", "UK"])<br><br>
              gr.<func>Interface(</func><varl>fn</varl>=<func>outbreak_forecast</func>, 
              <varl>inputs</varl>=[r, month, countries, "checkbox"], <varl>outputs</varl>="plot"<func>)</func>.<func>launch()</func>
            </code></div>
        </div>
        <div class="instructions">
          Provide the parameters below and click submit to view the forecast of a simulated disease outbreak. This is <strong>not</strong> based on an actual disease and uses synthetic data.
        </div>
        <div id="interface_4"></div>
      </div>      
    </div>
    <div id="logos">
      <h5>Works with these libraries</h5>
      <div id="logo_set" class="container">
        <img src="static/home/img/logos/tf.png">
        <img src="static/home/img/logos/pytorch.png">
        <img src="static/home/img/logos/jupyter.png">
        <img src="static/home/img/logos/colab.png">
        <img src="static/home/img/logos/matplotlib.png">
        <img src="static/home/img/logos/scikit.png">
      </div>
    </div>
    <div id="summaries" class="container">
      <div id="setup" class="summary_box">
        <h3>Fast, easy setup</h3>
        <p>Gradio can be installed directly through pip. Creating a Gradio interface only requires adding a couple lines of code to your project. You can choose from a variety of interface types to interface your function.</p>
        <p>More on <a href="getting_started">Getting Started >></a>
        <p>
      </div>
      <div id="present" class="summary_box">
        <h3>Present and share</h3>
        <p>Gradio can be embedded in Python notebooks or presented as a webpage. A Gradio interface can automatically generate a public link you can share with colleagues that lets them interact with the model on your computer remotely from their own devices.</p>
        <p>More on <a href="getting_started#sharing">Sharing >></a>
        <p>
      </div>
    </div>
    <div class="container" id="contact-box">
      <h3>Contact Us.</h3>
      <p>Want to integrate Gradio in a large team? We can help with <b>Gradio for Teams</b>. Get in touch.</p>
      <form method="POST" action="https://formspree.io/admin@gradio.app">
        <input type="text" name="email" id="email" placeholder="Email">
        <button type="submit" id="submit" class="primary">Submit</button>
      </form>
      <p>Running into any issues? Contact us directly with any questions
        <a href="mailto:team@gradio.app" target="_blank">here</a>, or <a
                href="https://github.com/gradio-app/gradio-UI/issues/new/choose" target="_blank">open an issue</a>
        at our github repo.</p>
    </div>
  </main>
  <footer>
    <div id="footer-set" class="container">
      <img id="bottom-logo" src="static/home/img/logo_inline.png" />
      <div>
        <a href="https://twitter.com/teamGradio" target="_blank"><img class="social-logo" src="static/home/img/twitter.png" /></a>
        <a href="https://github.com/gradio-app/gradio-UI"><img class="social-logo" src="static/home/img/github.svg" /></a>
      </div>
    </div>
  </footer>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  {% include 'footer.html' %}
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.5.2/dist/tf.min.js"></script>
  <script>
    $(".demo-link").click(function() {
      let demo_num = $(this).attr("demo");
      $(".demo-link").removeClass("selected");
      $(this).addClass("selected");
      $(".demo-window").hide();
      $(`.demo-window[demo="${demo_num}"]`).show();      
    })
 
    canvas = document.createElement("canvas");
    ctx = canvas.getContext("2d");
    last_sketch = null;
    last_output = null;

    cached_input = null;
    cached_output = null;
    tf.loadLayersModel('static/home/mnist/model.json').then(function(model) {
      window.model = model;
      var iface1 = gradio({
        "input_interfaces": [
          ["sketchpad", {"label": "sketch"}]
        ],
        "output_interfaces": [
          ["label", {"label": "classification"}]
        ],
        "function_count": 1,
        "live": true,
        "refresh_lag": 150,
        "show_input": true,
        "show_output": true
      }, function(data) {
        return new Promise((resolve, reject) => {
          var img = new Image();
          img.onload = function() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(img, 0, 0, 28, 28);
            img_data = ctx.getImageData(0, 0, 28, 28).data;
            var input = [];
            for (var i = 0; i < img_data.length; i += 4) {
              input.push(img_data[i + 3] / 255);
            }
            if (JSON.stringify(data) == JSON.stringify(cached_input)) {
              resolve(cached_output);
            } else if (Math.max(...input) == 0) {
              if (cached_input == null) {
                console.log("predict");
                window.model.predict([tf.tensor(new Array(28 * 28).fill(0)).reshape([1, 28, 28, 1])]);
              }
              let result = {
                "label": "",
              }
              cached_output = {"data": [result]};
              resolve(cached_output);
            } else if (window.model) {
              console.log("predict 2");
              window.model.predict([tf.tensor(input).reshape([1, 28, 28, 1])]).array().then(function(scores){
                scores = scores[0];
                let labeled_scores = []
                for ([i, score] of scores.entries()) {
                  labeled_scores.push([i, score]);
                }
                labeled_scores.sort(function(a, b) {
                  return b[1] - a[1];
                })
                let confidences = [];
                for (let i = 0; i < 4; i++) {
                  l_score = labeled_scores[i];
                  confidences.push({
                    "label": l_score[0], 
                    "confidence": l_score[1]
                  })
                }
                let result = {
                  "label": labeled_scores[0][0],
                  "confidences": confidences
                }
                cached_output = {"data": [result]};
                resolve(cached_output);
              });
            };
            cached_input = data;
          }
          img.src = data[0];
        });              
      }, "#interface_1");
    })
    
    configs = {{configs|tojson}};
    var iface2 = gradio_url(configs[0], "/model/0", "#interface_2");

    var has_clicked_3 = false;
    $(".demo-link[demo=3]").click(function() {
      if (has_clicked_3) {
        return;
      }
      has_clicked_3 = true;
      var iface3 = gradio_url(configs[1], "/model/1", "#interface_3");
    })

    var iface4 = gradio_url(configs[2], "/model/2", "#interface_4");

    if (window.location.href.includes("#contact")) {
      window.setTimeout(function() {
        $("#contact-box").addClass("flash")
      }, 200);
    }
    $("#contact-link").click(function() {
      $("#contact-box").removeClass("flash")
      window.setTimeout(function() {
        $("#contact-box").addClass("flash")
      }, 100);
    })
    </script>
  <body>

</html>